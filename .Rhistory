pu1_maf <- read.maf(maf = snps_pu1, clinicalData = phenoTable)
pu1_maf
## -------------------
# General plots
## -------------------
plotmafSummary(maf = pu1_maf, rmOutlier = F, addStat = 'median', dashboard = TRUE, titvRaw = F )
hist <- phenoTable %>% filter(disease == "HISTIO") %>% select(Tumor_Sample_Barcode)
histio <- subsetMaf(maf = pu1_maf, tsb = hist$Tumor_Sample_Barcode,mafObj = T)
plotmafSummary(maf = histio, rmOutlier = F, addStat = 'median', dashboard = TRUE, titvRaw = F )
##--------------------------------------------------
# Load libraries
##--------------------------------------------------
library(dplyr)
library(tibble)
library(GenomicRanges)
library(maftools)
##--------------------------------------------------
# Source files
##--------------------------------------------------
source("/juno/work/geissmann/data/Microglia/code_snippets/get.mutations.by.project.R")
#dataset_name <- "DN_vs_NEUN_PU1"
dataset_name <- "PU_1_vs_NEUN_DN"
##-------------------------------------------------------------------
## 1. Calling mutations from the Shearwater output files
##-------------------------------------------------------------------
baits = read.table(file = "/juno/work/geissmann/data/Microglia/shearwaterML/HemePACT_v4_b37_targets.bed", header = 0, stringsAsFactors = F)
baits = GRanges(baits[,1], IRanges(baits[,2],baits[,3]))
numsegments_per_job = 20
entry_start = seq(from = 1, to = length(baits), by = numsegments_per_job)
entry_end = pmin(entry_start+numsegments_per_job-1, length(baits))
##------------------------------------------------------------------
# 2. Loading the table of putative mutations from each patient
##------------------------------------------------------------------
mutations <- NULL
for (h in 1:length(entry_start)) {
cat("Going for file=",sprintf("/juno/work/geissmann/data/Microglia/%s/shearwater_temp_%s/mismatches_%s_%s.txt", dataset_name,dataset_name, entry_start[h], entry_end[h]),"\n");
m = read.table(file=sprintf("/juno//work/geissmann/data/Microglia/%s/shearwater_temp_%s/mismatches_%s_%s.txt", dataset_name,dataset_name, entry_start[h], entry_end[h]), header = 1, sep="\t", stringsAsFactors = F)
mutations = rbind(mutations,m)
}
indels_f <- length(grep("[-I]",mutations[,"mut"]));
subs_f   <- nrow(mutations)-indels_f;
cat("#INITIAL_NUMBER_OF_MUTATIONS\t",nrow(mutations),"\t",indels_f,"\t",subs_f,"\t",indels_f/(indels_f+subs_f),"\n",sep="");
mutations$mut_site <- paste(mutations$chr,mutations$pos,mutations$ref,mutations$mut);
##---------------------------------------------------------------------------------------------------
# 3. Let's merge neighbor indels and check they have consistent VAFs ( fa8:)
##---------------------------------------------------------------------------------------------------
#rownames(mutations) <- paste(mutations$sampleID,mutations$chr,mutations$pos,mutations$muts,sep="|")
indels         <- mutations[which(mutations$mut=="-"),];
indels         <- indels[order(indels$sampleID, indels$chr, indels$pos),];
i              <- 1;
group_counter  <- 1;
while(i <= nrow(indels)) {
indel_from  <- indels[i,"pos"];
indel_to    <- indel_from;
from_index  <- i;
to_index    <- i;
deleted_seq <- indels[i,"ref"];
sample_f    <- indels[i,"sampleID"];
i <- i+1;
if(i>nrow(indels)) {
break;
}
for(j in c(i:nrow(indels))) {
if(j>nrow(indels)) {
i <- j
break; #finish
}
else if(indels[j,"pos"]>(indels[(j-1),"pos"]+1)) {
i <- j; #start a new indel
break;
} else {
if(indels[j,"chr"] != indels[(j-1),"chr"]) {
i <- j; #start a new indel
break;
} else {
#This is a candidate, but check their VAFs are compatible with a Fishers exact test:
mat <- matrix(nrow=2,ncol=2,0);
#mat[1,] <- c(indels[max(i,j-1),  "xfw"]+indels[max(i,j-1),  "xbw"], indels[max(i,j-1),  "nfw"]+indels[max(i,j-1),  "nbw"])
mat[1,] <- c(indels[j-1,  "xfw"]+indels[j-1,  "xbw"], indels[j-1,  "nfw"]+indels[j-1,  "nbw"])
mat[2,] <- c(indels[j,    "xfw"]+indels[j,    "xbw"], indels[j,    "nfw"]+indels[j,    "nbw"])
mat[1,2] <- mat[1,2]-mat[1,1];
mat[2,2] <- mat[2,2]-mat[2,1];
pvalue <- fisher.test(mat)$p.value;
if(pvalue < 0.01) {
cat(" Breaking up indel because VAFs do not match\n");
cat("             ",j-1, " vs ", j, ": pval=", pvalue, " [",indels[j-1,"pos"],"-",indels[j,"pos"],"]",sep="");
cat("    (mat=", mat[1,1],",",mat[1,2],",",mat[2,1],",",mat[2,2],")\n",sep="");
i <- j;
break;
}
indel_to <- indels[j,"pos"];
to_index <- j;
deleted_seq <- paste(deleted_seq,indels[j,"ref"],sep="");
}
}
}
#cat("   [Sample=",sample_f,"] Indel goes from=",indel_from,", to=", indel_to," [",deleted_seq,">-]\n",sep="");
indels[c(from_index:to_index),"groupID"    ] <- group_counter;
indels[c(from_index:to_index),"deleted_seq"] <- deleted_seq;
group_counter <- group_counter + 1;
}
mutations[rownames(indels),"indel_group"] <- indels$groupID
mutations[rownames(indels),"deleted_seq"] <- indels$deleted_seq
##-----------------------------------------------------------------------------------------------
# 4. Identifying putative germline or somatic indels to flag mutations near them
##-----------------------------------------------------------------------------------------------
L <- sum(end(reduce(baits))-start(reduce(baits))+1) # Bait footprint
putative_indelsites = mutations[mutations$mut %in% c("-","INS"),]
s <- unique(mutations$sampleID) # List of samples from this patient
putative_indelsites$qval <- p.adjust(putative_indelsites$pval, method="BH",n=L*length(s)*2)
putative_indelsites <- unique(putative_indelsites[putative_indelsites$qval<0.20, c("sampleID","chr","pos")])
indel_flank <- 10
putative_indelsites_gr <- GRanges(putative_indelsites$chr, IRanges(putative_indelsites$pos-indel_flank, putative_indelsites$pos+indel_flank))
##-----------------------------------------------------------------------------------------------
# 5. Removing germline SNPs:
# - Any mutation present in >20% of all reads across samples (a low cutoff to remove germline indels too, as they present lower VAFs)
# fa8: This filter is not appropriate for all cases. For example, when there is just one bladder disk in a patient.
# fa8: The removal of germline SNPs is the piece that needs more adjustments from project to project
##-----------------------------------------------------------------------------------------------
mutations <- unique(mutations);
mutations$label <- "";
mutations[which(mutations$tum_globalvaf >= 0.35),"label"] <- "germline"; # Mati: Changed this to 35%, BRAF present in ~20% in some patients
table(mutations$label)
#remove the germline:
if(length(which(mutations$label == "germline")) > 0) {
mutations <- mutations[-which(mutations$label == "germline"),]
}
indels_f <- length(grep("[-I]",mutations[which(mutations$label == ""),"mut"]));
subs_f   <- nrow(mutations[which(mutations$label == ""),])-indels_f;
cat("#AFTER_GLOBAL_VAF\t",nrow(mutations),"\t",indels_f,"\t",subs_f,"\t",indels_f/(indels_f+subs_f),"\n",sep="");
##-----------------------------------------------------------------------------------------------
# 6.Coverage filter: remove muts with too low cov... analyse cov stats
##-----------------------------------------------------------------------------------------------
mutations$base_counts <- apply(mutations[,c("xfw","xbw","nfw","nbw")],1,sum)
mutations             <- mutations[which(mutations$base_counts > 30),]
indels_f <- length(grep("[-I]",mutations[which(mutations$label==""),"mut"]));
subs_f   <- nrow(mutations[which(mutations$label==""),])-indels_f;
cat("#AFTER_COVERAGE_FILTER\t",nrow(mutations),"\t",indels_f,"\t",subs_f,"\t",indels_f/(indels_f+subs_f),"\n",sep="");
##-----------------------------------------------------------------------------------------------
# 7.Filter for germline mutations
##-----------------------------------------------------------------------------------------------
mutations$vaf <- (mutations$xfw+mutations$xbw)/(mutations$nfw+mutations$nbw)
mutations$vaf_label <- "";
mutations[which(mutations$vaf >= 0.35),"vaf_label"] = "germline";
table(mutations$vaf_label)
#remove the germline:
if(length(which(mutations$vaf_label == "germline")) > 0) {
mutations <- mutations[-which(mutations$vaf_label == "germline"),]
}
indels_f <- length(grep("[-I]",mutations[which(mutations$vaf_label == ""),"mut"]));
subs_f   <- nrow(mutations[which(mutations$vaf_label == ""),])-indels_f;
cat("#AFTER_GLOBAL_VAF\t",nrow(mutations),"\t",indels_f,"\t",subs_f,"\t",indels_f/(indels_f+subs_f),"\n",sep="");
##-------------------------------------------------------------------------------------------------------
# 8. FDR calculation: significant mutations (after removing SNPs, to avoid inflating the FDR adjustment)
##--------------------------------------------------------------------------------------------------------
L < sum(end(reduce(baits))-start(reduce(baits))+1) # Bait footprint
mutations$qval = p.adjust(mutations$pval, method="BH", n=L*length(s)*5) # Mati: removed , n=L*length(s)*5
mutations[which(mutations$qval >= 0.01),"label"] = "no-fdr;";
table(mutations$label)
prefdr.mutations <- mutations;                        # This will be the matrix used for the rescuing
prefdr.mutations[which(prefdr.mutations$qval < 0.01), "label"] = "sig;";
table(prefdr.mutations$label)
mutations <- mutations[which(mutations$qval < 0.01),]; # To make the matrix smaller
mutations <- mutations[order(mutations$chr,mutations$pos),]
mutations$vaf <- (mutations$xfw+mutations$xbw)/(mutations$nfw+mutations$nbw)
indels_f <- length(grep("[-I]",mutations[which(mutations$label == ""),"mut"]));
subs_f   <- nrow(mutations[which(mutations$label == ""),])-indels_f;
cat("#AFTER_FDR\t",nrow(mutations),"\t",indels_f,"\t",subs_f,"\t",indels_f/(indels_f+subs_f),"\n",sep="");
##---------------------------------------------------------------------------------------------------------------------------
# 9. Requesting at least 1 supporting read from both strands and annotating substitutions near indels (somatic or germline)
##--------------------------------------------------------------------------------------------------------------------------
#rmpos = (mutations$mut %in% c("-","INS")) & (mutations$xfw==0 | mutations$xbw==0) # Asking for 1 supporting read in both strands only for indels
rmpos <- (mutations$xfw==0 | mutations$xbw==0) # Asking for 1 supporting read in both strands for all mutations
filt2 <- mutations[rmpos,];
if(nrow(filt2)>0) {
filt2$filter = "Strandness"
}
mutations[rmpos,"label"] = paste(mutations[rmpos,"label"],"strandness;",sep="");
#####mutations = mutations[!rmpos,]
samples = unique(mutations$sampleID)
rmpos = NULL
for (h in 1:length(samples)) {
m = mutations[mutations$sampleID==samples[h] & !(mutations$mut %in% c("-","INS")),]
m_gr = GRanges(m$chr, IRanges(m$pos,m$pos))
i_gr = putative_indelsites_gr[putative_indelsites$sampleID==samples[h]]
ol = as.matrix(suppressWarnings(findOverlaps(m_gr, i_gr, type="any", select="all")))
rmpos = c(rmpos, rownames(m)[unique(ol[,1])])
}
filt3 = mutations[rmpos,];
if(nrow(filt3) > 0) {
filt3$filter = "Near_indel"
}
mutations[rmpos,"label"] = paste(mutations[rmpos,"label"],"near_indel;",sep="");
table(mutations$label)
mutations[which(mutations$label == ""),"label"] <- "OK;";
table(mutations$label)
mutations[which(mutations$label == ""),"label"] <- "OK";
ok_muts <- mutations[grep("OK",mutations$label),      ]
sub  <- ok_muts[grep("[-I]",ok_muts[,"mut"],invert=T),]
ins  <- ok_muts[grep("I",   ok_muts[,"mut"]),         ]
#del  <- ok_muts[grep("-",   ok_muts[,"mut"]),         ]  # CORRECTION SUGGESTED BY ANDREW
del  <- mutations[grep("-",   mutations[,"mut"]),         ]
sub  <- sub[order(sub$sampleID, sub$chr, sub$pos),    ]
ins  <- ins[order(ins$sampleID, ins$chr, ins$pos),    ]
del  <- del[order(del$sampleID, del$chr, del$pos),    ]
#To store the new data
new_mutations <- mutations[0,]
View(new_mutations)
# Deletions (defined in mutations$indel_group):
# For every "OK" deletion, get its del-groupID and find all the other deletions belonging
# to that group. Merge them and create a new entry in mutations: combine pvalues, vaf, etc
# For every "OK" deletion first check it hasn't been already merged
for(j in 1:nrow(del)) {
indel_group       <- del[j,"indel_group"]
if(nrow(new_mutations[which(new_mutations$indel_group==indel_group),]) > 0) {
next; #we already have one from the group of indels
}
indels_from_group                                  <- mutations[which(mutations$indel_group==indel_group),]
new_mutations                                      <- rbind(new_mutations,indels_from_group[1,])
new_mutations[nrow(new_mutations),"pos"          ] <- min  (indels_from_group$pos              )
new_mutations[nrow(new_mutations),"vaf"          ] <- mean (indels_from_group$vaf              )
new_mutations[nrow(new_mutations),"tum_globalvaf"] <- mean (indels_from_group$tum_globalvaf    )
new_mutations[nrow(new_mutations),"pval"         ] <- min  (indels_from_group$pval             )
new_mutations[nrow(new_mutations),"qval"         ] <- min  (indels_from_group$qval             )
new_mutations[nrow(new_mutations),"label"        ] <- paste(indels_from_group$label,collapse="")
new_mutations[nrow(new_mutations),"ref"          ] <- indels_from_group[1,"deleted_seq"]
}
View(new_mutations)
# Insertions. No need to look for consecutive INS. Just add them to new_mutations
new_mutations <- rbind(new_mutations,ins);
View(new_mutations)
# Substitutions: merge consecutive... [using IÃ±igo's code]
d = sub$pos-(1:nrow(sub))
runs = rle(d)
rmpos = rep(0,nrow(sub))
runstarts = cumsum(runs$length)-runs$length+1
for (h in 1:length(runs$length)) {
if (runs$length[h]>1) { # Adjacent mutations
mutcluster                         = runstarts[h]:(runstarts[h]+runs$lengths[h]-1)
rmpos[mutcluster[-1]             ] = 1 # Removing all the affected rows except the first one (which we will edit to capture the complex event)
sub[mutcluster[1],"ref"          ] = paste(sub[mutcluster,"ref"          ],collapse="")
sub[mutcluster[1],"mut"          ] = paste(sub[mutcluster,"mut"          ],collapse="")
sub[mutcluster[1],"mu"           ] = mean (sub[mutcluster,"mu"           ]            )
sub[mutcluster[1],"tum_globalvaf"] = mean (sub[mutcluster,"tum_globalvaf"]            )
sub[mutcluster[1],"vaf"          ] = mean (sub[mutcluster,"vaf"          ]            )
sub[mutcluster[1],"pval"         ] = min  (sub[mutcluster,"pval"         ]            )
sub[mutcluster[1],"qval"         ] = min  (sub[mutcluster,"qval"         ]            )
}
}
sub = sub[!rmpos,]
new_mutations <- rbind(new_mutations,sub);
View(new_mutations)
mutations.old <- mutations
mutations     <- new_mutations
mutations[which(mutations$label == ""),"label"] <- "OK;";
mutations <- mutations[grep("OK",mutations$label),      ]
View(mutations)
indels_f <- length(grep("[-I]",mutations[,"mut"]));
subs_f   <- nrow(mutations)-indels_f;
cat("#AFTER_MERGING_RUNS\t",nrow(mutations),"\t",indels_f,"\t",subs_f,"\t",indels_f/(indels_f+subs_f),"\n",sep="");
mutations[grep("OK",mutations$label)
,]
Proj_07973_P_CMO_MAF <- read.delim("/juno/work/geissmann/data/Microglia/Archived results/MAFs/Proj_07973_P_CMO_MAF.txt")
View(Proj_07973_P_CMO_MAF)
table(Proj_07973_P_CMO_MAF$Tumor_Sample_Barcode)
789+1338
## Directories of projects
my_dirs <- c("/ifs/res/share/geissmaf/geissmaf/Proj_07973_P/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_AL/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_AN/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_AO/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_AU/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_A_VWT/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_AX/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_AY/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_AZ/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_BA/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_BF/r_001/alignments",
# "/ifs/res/share/geissmaf/geissmaf/Proj_07973_BK/r_001/alignments", DONT RUN
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_BL/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_BM/r_002/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_BO/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_BV/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_CA/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_K/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_R/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_Z/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_CQ/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_CS/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_CK/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_CF/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_BU_BY/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_DF/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_CZ/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_CU/r_002/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_DA/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_DL/r_001/alignments",
"/ifs/res/share/geissmaf/geissmaf/Proj_07973_DN/r_001/alignments")
## Read the BAM filenames in those documentaries
files <- list.files(my_dirs, pattern = "*.bam", full.names = T)
files
##--------------------------------------------------
## Create Blood files
##--------------------------------------------------
keep_Blood  = grepl("B.bam", files)
keep_Blood
## Read the BAM filenames in those documentaries
files <- list.files(my_dirs, pattern = "*.bam", full.names = T)
files
##--------------------------------------------------
## Create Blood files
##--------------------------------------------------
keep_Blood  = grepl("B.bam", files)
##--------------------------------------------------
## Create Blood files
##--------------------------------------------------
keep_Blood  = grepl("B.bam", files) | grepl("MONO", files)) | grepl("LIN", files)) | grepl("Biopsy", files)) | grepl("BM2", files))
##--------------------------------------------------
## Create Blood files
##--------------------------------------------------
keep_Blood  = grepl("B.bam", files) | grepl("MONO", files) | grepl("LIN", files) | grepl("Biopsy", files) | grepl("BM2", files)
files
##--------------------------------------------------
## Create Blood files
##--------------------------------------------------
keep_Blood  = grepl("B.bam", files) | grepl("MONO.bam", files) | grepl("LIN", files) | grepl("Biopsy", files) | grepl("BM2", files)
grepl("MONO.bam", files)
files
grepl("LIN", files)
grepl("Biopsy", files)
grepl("BM2", files)
grepl("MONO.bam", files)
##--------------------------------------------------
## Create Blood files
##--------------------------------------------------
keep_Blood  = grepl("B.bam", files) | grepl("MONO.bam", files) | grepl("LIN", files) | grepl("Biopsy", files) | grepl("BM2", files)
files_Blood = files[keep_Blood]
keep_Blood  = grepl("B.bam", files)
files_Blood = files[keep_Blood]
##--------------------------------------------------
## Create Blood files
##--------------------------------------------------
keep_Blood  = grepl("B.bam", files) | grepl("MONO.bam", files) | grepl("LIN", files) | grepl("Biopsy", files) | grepl("BM2", files)
files_Blood = files[keep_Blood]
files_Blood
write.table(x = files_Blood, file = "/juno/work/geissmann/data/Microglia/files_Blood.txt", sep = "\t", row.names = F, col.names = F)
setwd("~/Documents/GitHub/TEMo-classifier")
##------------------------------------------
# Load libraries
##------------------------------------------
library(pROC)
library(caret)
library(dplyr)
install(:pROC)
install("pROC")
install("caret")
##------------------------------------------
# Load libraries
##------------------------------------------
library(pROC)
library(caret)
library(dplyr)
##------------------------------------------
# Source files
##------------------------------------------
source(file = "Classification_Analysis/tidy_code/import.normalise.data.R")
source(file = "Classification_Analysis/tidy_code/run.ComBat.R")
##------------------------------------------
# Source files
##------------------------------------------
source(file = "helpFunctions/import.normalise.data.R")
source(file = "helpFunctions/run.ComBat.R")
source(file = "helpFunctions/my.pca.R")
source(file = "helpFunctions/corr.filtering.R")
source(file = "helpFunctions/periodontitis.data.R")
source(file = "helpFunctions/ensembl.to.GS.R")
source(file = "helpFunctions/plot.ROC.R")
source(file = "helpFunctions/run.RF.RFE.R")
#### Import and normalise gene expression monocyte data
dlist <- Import.normalise.data()
#### Import and normalise gene expression monocyte data
dlist <- Import.normalise.data()
##------------------------------------------
# Source files
##------------------------------------------
source(file = "helpFunctions/import.normalise.data.R")
#### Import and normalise gene expression monocyte data
dlist <- Import.normalise.data()
##------------------------------------------
# Source files
##------------------------------------------
source(file = "helpFunctions/import.normalise.data.R")
#### Import and normalise gene expression monocyte data
dlist <- Import.normalise.data()
#### PCA plot before batch effect correction
my.pca(dlist$lcpm, dge = dlist$dge)
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
install("sva")
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
source(file = "helpFunctions/run.ComBat.R")
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
dlist$dge
dlist$lcpm
pheno <- data.frame(Snames = colnames(dlist$dge), Group = dlist$dge$samples$group, Batch = dlist$dge$samples$batch)
colnames(dlist$dge)
dge
dlist$dge
dlist$dge$samples
colnames(dlist$dge$samples$files)
dlist$dge$samples$files
dlist$dge$samples$group
pheno <- data.frame(Snames = dlist$dge$samples$files, Group = dlist$dge$samples$group, Batch = dlist$dge$samples$batch)
#### Model matrix including the group but not the sorting protocol
modcombatCoef <- model.matrix(~as.factor(Group), data=pheno)
source(file = "helpFunctions/run.ComBat.R")
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
##------------------------------------------
# Load libraries
##------------------------------------------
require(sva)
library(mgcv)
library(vegan)
library(mgcv)
remove.packages(sva)
remove.packages("sva")
install("sva")
source(file = "helpFunctions/run.ComBat.R")
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
sva::ComBat()
source(file = "helpFunctions/run.ComBat.R")
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
dlist$dge
source(file = "helpFunctions/run.ComBat.R")
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
remove.packages("mgcv")
install.packages("mgcv")
install.packages("mgcv")
library(mgcv)
source(file = "helpFunctions/run.ComBat.R")
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
source(file = "helpFunctions/run.ComBat.R")
#### Correct data for batch effects using Combat
combatEdata <- run.ComBat(dge = dlist$dge, mat = dlist$lcpm)
#### PCA plot after batch effect correction
my.pca(combatEdata, dge = dlist$dge)
data <- combatEdata
class <- as.factor(dlist$dge$samples$group)
class <- relevel(class, "Cancer")
data <- t(data)
dim(data)
data_fr <- data.frame(data, class = class)
#### Split dataset into training (70%) and testing (30%)
set.seed(12)
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(data_fr$class, p = 0.7, list=FALSE)
library(caret)
library(dplyr)
##------------------------------------------
# Load libraries
##------------------------------------------
library(pROC)
?require
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(data_fr$class, p = 0.7, list=FALSE)
# Step 2: Create the training  dataset
trainData <- data_fr[trainRowNumbers,]
dim(trainData)
# Step 3: Create the test dataset
testData <- data_fr[-trainRowNumbers,]
dim(testData)
#### Filtering based on linear correlation
reducedDataList <- corr.filtering(trainData = trainData)
reducedtData <- reducedDataList$reducedtData
dim(reducedtData)
install.packages("feseR")
install("feseR")
library(BiocManager)
install("feseR")
install.packages("devtools")
library(devtools)
install_github("enriquea/feseR")
library(feseR)
install("ggbiplot")
install_github("vqv/ggbiplot")
install_github("enriquea/feseR")
#### Filtering based on linear correlation
reducedDataList <- corr.filtering(trainData = trainData)
library(feseR)
#### Filtering based on linear correlation
reducedDataList <- corr.filtering(trainData = trainData)
require(dplyr)
tData <- trainData %>% dplyr::select(-c("class"))
cT <-  trainData %>% select(c("class"))
cT$class <- ifelse(cT$class == "Normal","0","1")
tData <- as.matrix(tData)
cT$class <- as.numeric(cT$class)
cT <- as.matrix(cT$class)
reduced.tData <- filter.corr(features = tData, class = cT, mincorr = 0.4)
dim(reduced.tData)
reduced.tData <- filter.corr(features = tData, class = cT, mincorr = 0.4)
feseR::filter.corr()
reduced.tData <- feseR::filter.corr(features = tData, class = cT, mincorr = 0.4)
